# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

This is a Retrieval Augmented Generation (RAG) application built on Cloudflare Workers that demonstrates how to combine vector embeddings, database storage, and AI text generation. The application allows users to store notes in a knowledge base and query them using natural language, with AI-generated responses enhanced by relevant context from the stored notes.

## Core Architecture

### Application Stack
- **Framework**: Hono (lightweight web framework)
- **Runtime**: Cloudflare Workers
- **Storage**: D1 (SQLite database) for note text storage
- **Vector Search**: Vectorize for semantic similarity search
- **AI Models**:
  - Default: Workers AI with `@cf/meta/llama-3.1-8b-instruct`
  - Optional: Anthropic Claude (`claude-3-5-sonnet-latest`) when `ANTHROPIC_API_KEY` is set
- **Embeddings**: `@cf/baai/bge-base-en-v1.5` model
- **Orchestration**: Cloudflare Workflows for async note processing
- **Text Processing**: LangChain's `RecursiveCharacterTextSplitter` (configurable via `ENABLE_TEXT_SPLITTING`)

### Key Components

**src/index.ts** - Main application file containing:
- Hono app with REST endpoints
- `RAGWorkflow` class that handles note ingestion pipeline:
  1. Optional text splitting into chunks
  2. Database record creation (one per chunk)
  3. Embedding generation for each chunk
  4. Vector index insertion

**Workflow Pattern**: When a new note is added via `POST /notes`, the RAG workflow is triggered asynchronously. The workflow splits text (if enabled), creates database records, generates embeddings, and stores vectors - all tracked as separate workflow steps for reliability.

**RAG Query Flow** (GET / endpoint):
1. Convert user question to embeddings
2. Query vector index for top 3 similar notes
3. Retrieve matching note text from D1
4. Construct context from notes
5. Generate AI response using context

### Database Schema

```sql
CREATE TABLE notes (
  id TEXT PRIMARY KEY,
  text TEXT NOT NULL
);
```

The `id` field is auto-generated by D1 and used as the vector ID in Vectorize for matching database records to vector search results.

## Development Commands

### Local Development
```bash
npm install                    # Install dependencies
npm run start                 # Start local dev server (wrangler dev)
```

### Deployment
```bash
npm run deploy                # Deploy to Cloudflare Workers (wrangler deploy)
```

### Database Operations
```bash
# Create new D1 database
wrangler d1 create DATABASE

# Apply migrations locally
wrangler d1 migrations apply DATABASE

# Apply migrations to production
wrangler d1 migrations apply DATABASE --remote

# Query database directly (local)
wrangler d1 execute DATABASE --command="SELECT * FROM notes"

# Query database directly (remote)
wrangler d1 execute DATABASE --remote --command="SELECT * FROM notes"
```

### Vector Index Operations
```bash
# Create vector index (must match embedding model dimensions)
wrangler vectorize:index create VECTOR_INDEX --preset "@cf/baai/bge-base-en-v1.5"
```

### Configuration

**wrangler.jsonc** (JSON with comments format) must include bindings for:
- `AI` - Workers AI binding
- `DATABASE` - D1 database binding with `database_id`
- `VECTOR_INDEX` - Vectorize index binding with `index_name`
- `RAG_WORKFLOW` - Workflow binding with `class_name = "RAGWorkflow"`

### Secrets Management
```bash
# Enable Anthropic Claude (optional)
wrangler secret put ANTHROPIC_API_KEY
```

## API Endpoints

- `GET /` - Query AI with `?text=<question>` parameter, returns text response
- `GET /ui` - HTML form interface for asking questions
- `GET /write` - HTML form interface for adding notes
- `POST /notes` - Add note to knowledge base (JSON body with `text` field)
- `GET /notes` - HTML view of all notes
- `GET /notes.json` - JSON array of all notes
- `DELETE /notes/:id` - Delete note from both D1 and Vectorize

## Configuration Options

**ENABLE_TEXT_SPLITTING** (wrangler.jsonc `vars` section):
- `true` (default): Uses `RecursiveCharacterTextSplitter` to break large texts into chunks
- `false`: Stores entire text as single note/embedding

Text splitting is recommended for long documents to improve retrieval accuracy. Customize chunk size/overlap in src/index.ts:150-151.

## Model Switching

The application automatically uses Anthropic Claude if `ANTHROPIC_API_KEY` secret is set, otherwise falls back to Workers AI Llama model. The model used is returned in the `x-model-used` response header.

## TypeScript

TypeScript configuration is in tsconfig.json. The project uses:
- `@cloudflare/workers-types` (v4.20251111.0) for Workers API types
- Target: ES2022 with ESNext modules
- Module resolution: bundler (optimized for Cloudflare Workers)
- Strict type checking enabled

**Important**: When using Workers AI embeddings API, always wrap text in an array and add type assertion:
```typescript
const embeddings = await env.AI.run('@cf/baai/bge-base-en-v1.5', {
  text: [question]
}) as { data: number[][] }
```

## Recent Updates (2025)

This repository has been modernized with the following updates:

### Dependencies
- **Wrangler**: Upgraded to v4.46.0 (from v3.22.4)
  - Now uses esbuild v0.24 (security fix)
  - Local mode by default for all commands
- **Anthropic SDK**: v0.68.0 (from v0.32.1)
- **LangChain Text Splitters**: v1.0.0 (from v0.1.0)
- **Hono**: v4.10.4 (from v4.5.6)
- **TypeScript**: v5.9.3 (from v5.6.3)

### Configuration
- Converted from wrangler.toml to wrangler.jsonc (JSON with comments format)
- Compatibility date updated to 2025-01-10
- TypeScript target updated to ES2022
- Module resolution set to "bundler" for better Workers compatibility

### Known Limitations
- Vectorize bindings do not support local development; use remote bindings for testing vector operations
- AI bindings always access remote resources and may incur usage charges even in local dev
